{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    cohen_kappa_score,\n",
    "    classification_report,\n",
    ")\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DonID_standardized</th>\n",
       "      <th>UrlName</th>\n",
       "      <th>DonId</th>\n",
       "      <th>InformationType</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>Summary</td>\n",
       "      <td>The International Health Regulations (IHR) Nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>Overview</td>\n",
       "      <td>The IHR NFP of the Republic of South Africa no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>Epidemiology</td>\n",
       "      <td>Mpox is an infectious disease caused by the mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>The sudden appearance of unlinked cases of mpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>Advice</td>\n",
       "      <td>General&amp;nbsp;Health authorities and clinicians...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>2024-DON525</td>\n",
       "      <td>FurtherInformation</td>\n",
       "      <td>Standing recommendations for mpox issued by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-DON522</td>\n",
       "      <td>2024-DON522</td>\n",
       "      <td>2024-DON522</td>\n",
       "      <td>Summary</td>\n",
       "      <td>In December 2022, the Democratic Republic of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-DON522</td>\n",
       "      <td>2024-DON522</td>\n",
       "      <td>2024-DON522</td>\n",
       "      <td>Overview</td>\n",
       "      <td>Since 2022, an epidemic of mpox caused by monk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-DON522</td>\n",
       "      <td>2024-DON522</td>\n",
       "      <td>2024-DON522</td>\n",
       "      <td>Epidemiology</td>\n",
       "      <td>Mpox (monkeypox) is an infectious disease caus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DonID_standardized      UrlName        DonId     InformationType                                               Text\n",
       "0        2024-DON525  2024-DON525  2024-DON525             Summary  The International Health Regulations (IHR) Nat...\n",
       "1        2024-DON525  2024-DON525  2024-DON525            Overview  The IHR NFP of the Republic of South Africa no...\n",
       "2        2024-DON525  2024-DON525  2024-DON525        Epidemiology  Mpox is an infectious disease caused by the mo...\n",
       "3        2024-DON525  2024-DON525  2024-DON525          Assessment  The sudden appearance of unlinked cases of mpo...\n",
       "4        2024-DON525  2024-DON525  2024-DON525              Advice  General&nbsp;Health authorities and clinicians...\n",
       "5        2024-DON525  2024-DON525  2024-DON525  FurtherInformation  Standing recommendations for mpox issued by th...\n",
       "6        2024-DON522  2024-DON522  2024-DON522             Summary  In December 2022, the Democratic Republic of t...\n",
       "7        2024-DON522  2024-DON522  2024-DON522            Overview  Since 2022, an epidemic of mpox caused by monk...\n",
       "8        2024-DON522  2024-DON522  2024-DON522        Epidemiology  Mpox (monkeypox) is an infectious disease caus..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "who_data = pd.read_csv(\"../data/corpus.csv\")\n",
    "sub_data = who_data[0:9]\n",
    "sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIAPI:\n",
    "    def __init__(self, settings):\n",
    "        self.settings = settings\n",
    "\n",
    "    def gpt_response(self, message):\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                prompt=message,\n",
    "                temperature=self.settings[\"temperature\"],\n",
    "                max_tokens=self.settings[\"max_tokens\"],\n",
    "                model=self.settings[\"model\"],\n",
    "            )\n",
    "            gpt_answer = response[\"choices\"][0][\"text\"].strip(\"\\n\").lower()\n",
    "            return gpt_answer\n",
    "\n",
    "        except openai.error.RateLimitError as e:\n",
    "            # Handle rate limit error\n",
    "            print(f\"Rate limited. Error message: {e}\")\n",
    "            # Wait for 60 seconds before retrying\n",
    "            print(\"Waiting for 60 seconds to start again...\")\n",
    "            time.sleep(60)\n",
    "            # Retry the API call\n",
    "            return self.gpt_response(message)\n",
    "\n",
    "    def chatgpt_response(self, message):\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=self.settings[\"model\"],\n",
    "                messages=[{\"role\": \"user\", \"content\": message}],\n",
    "            )\n",
    "            chatgpt_answer = (\n",
    "                response[\"choices\"][0][\"message\"][\"content\"].strip(\"\\n\").lower()\n",
    "            )\n",
    "            return chatgpt_answer\n",
    "        except openai.error.RateLimitError as e:\n",
    "            # Handle rate limit error\n",
    "            print(f\"Rate limited. Error message: {e}\")\n",
    "            # Wait for the recommended duration before retrying\n",
    "            print(\"Waiting for 60 seconds to start again...\")\n",
    "            time.sleep(60)\n",
    "            # Retry the API call\n",
    "            return self.chatgpt_response(message)\n",
    "\n",
    "    def generate_response(self, data, prompt, model, ckpt):\n",
    "        i = 0\n",
    "        result = []\n",
    "        if ckpt:\n",
    "            with open(ckpt, \"rb\") as f:\n",
    "                result = pickle.load(f)\n",
    "            i = len(result)\n",
    "            data = data[i:]\n",
    "\n",
    "        for sent in data:\n",
    "            if len(sent) == 0:\n",
    "                break\n",
    "\n",
    "            print(i)\n",
    "            message = prompt.format(sent)\n",
    "\n",
    "            if model == \"gpt3\":\n",
    "                answer = self.gpt_response(message)\n",
    "            elif model in [\"chatgpt\", \"gpt4\", \"gpt-3.5-turbo\"]:\n",
    "                answer = self.chatgpt_response(message)\n",
    "            else:\n",
    "                raise ValueError(f\"Model {model} not recognized\")\n",
    "            result.append(answer)\n",
    "            i += 1\n",
    "\n",
    "            # Save partial response\n",
    "            CKPT = \"./results/ckpt/\"\n",
    "            if not os.path.exists(CKPT):\n",
    "                print(f\"{CKPT} does not exist. Creating...\")\n",
    "                os.mkdir(CKPT)\n",
    "            with open(f\"{CKPT}{model}_result_part.pkl\", \"wb\") as f:\n",
    "                pickle.dump(result, f)\n",
    "        print(\"---Done\")\n",
    "        return result\n",
    "\n",
    "\n",
    "def load_prompt(dir):\n",
    "    with open(dir) as f:\n",
    "        prompt = \"\".join(f.readlines())\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def get_confusion_matrix(data, label1, label2, output_dir):\n",
    "    true, pred = data[label1], data[label2]\n",
    "    true = true.to_numpy().reshape(-1)\n",
    "    pred = pred.to_numpy().reshape(-1)\n",
    "    mt = confusion_matrix(true, pred)\n",
    "\n",
    "    with open(output_dir.format(\"confusion_matrix\"), \"a\") as f:\n",
    "        f.write(f\"---{label1} & {label2} Matrix---\\n\")\n",
    "        f.write(np.array2string(mt) + \"\\n\\n\")\n",
    "\n",
    "\n",
    "def get_macrof1_score(data, label1, label2, output_dir):\n",
    "    true, pred = data[label1], data[label2]\n",
    "    score = f1_score(true, pred, average=\"macro\")\n",
    "    report = classification_report(true, pred, digits=3)\n",
    "    print(f\"Macro f1-score between {label1} & {label2}: {round(score, 3)}\")\n",
    "    print(\"---Classification Report created\")\n",
    "\n",
    "    with open(output_dir.format(\"macro_f1score\"), \"a\") as f:\n",
    "        f.write(f\"Macro f1-score between {label1} & {label2}: {round(score, 3)}\\n\")\n",
    "        f.write(report + \"\\n\")\n",
    "\n",
    "\n",
    "def get_kappa_score(data, label1, label2, output_dir):\n",
    "    true, pred = data[label1], data[label2]\n",
    "    score = cohen_kappa_score(true, pred)\n",
    "    print(f\"Cohen Kappa score between {label1} & {label2}: {round(score, 3)}\")\n",
    "\n",
    "    with open(output_dir.format(\"cohenKappa\"), \"a\") as f:\n",
    "        f.write(f\"Cohen Kappa score between {label1} & {label2}: {round(score, 3)}\\n\")\n",
    "\n",
    "\n",
    "def main(work, model, data, column_name, prompt_text, output_path, checkpoint=None):\n",
    "    if not os.path.exists(output_path):\n",
    "        print(f\"{output_path} does not exist. Creating...\")\n",
    "        os.mkdir(output_path)\n",
    "\n",
    "    settings = {\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 150,\n",
    "    }\n",
    "\n",
    "    if model == \"gpt3\":\n",
    "        settings[\"model\"] = \"text-davinci-003\"\n",
    "    elif model == \"gpt4\":\n",
    "        settings[\"model\"] = \"gpt-4\"\n",
    "    elif model in [\"chatgpt\", \"gpt-3.5-turbo\"]:\n",
    "        settings[\"model\"] = \"gpt-3.5-turbo\"\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model} not recognized\")\n",
    "\n",
    "    # Print column names to help identify the correct column\n",
    "    print(\"Available columns:\", data.columns)\n",
    "\n",
    "    # Check if the specified column exists in the dataset\n",
    "    if column_name not in data.columns:\n",
    "        raise KeyError(\n",
    "            f\"Column '{column_name}' does not exist in the dataset. Please check the column names.\"\n",
    "        )\n",
    "\n",
    "    if work == \"api\":\n",
    "        data = data[column_name]\n",
    "        prompt = prompt_text\n",
    "        output_file_path = os.path.join(output_path, f\"{model}-results.csv\")\n",
    "\n",
    "        api = OpenAIAPI(settings)\n",
    "        result = api.generate_response(data, prompt, model, checkpoint)\n",
    "\n",
    "        df = pd.DataFrame({column_name: data, f\"{model}-results\": result})\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "        print(\"Saved result file\")\n",
    "\n",
    "    elif work == \"quant\":\n",
    "        colnames = data.columns[1:]\n",
    "        output_file_path_template = os.path.join(output_path, f\"{model}-quant.txt\")\n",
    "        for label1, label2 in combinations(colnames, 2):\n",
    "            if label1 == \"label\":\n",
    "                get_confusion_matrix(data, label1, label2, output_file_path_template)\n",
    "                get_macrof1_score(data, label1, label2, output_file_path_template)\n",
    "                get_kappa_score(data, label1, label2, output_file_path_template)\n",
    "            elif label1 != \"label\":\n",
    "                get_kappa_score(data, label1, label2, output_file_path_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns: Index(['DonID_standardized', 'UrlName', 'DonId', 'InformationType', 'Text'], dtype='object')\n",
      "0\n",
      "Available columns: Index(['DonID_standardized', 'UrlName', 'DonId', 'InformationType', 'Text'], dtype='object')\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/ckpt/ does not exist. Creating...\n",
      "1\n",
      "./results/ckpt/ does not exist. Creating...\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Done\n",
      "Saved result file\n",
      "---Done\n",
      "Saved result file\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "work = \"api\"  # or 'quant'\n",
    "model = \"gpt-3.5-turbo\"  # or 'chatgpt', 'gpt4'\n",
    "prompt_text = \"Extract all causes and effects pairs that are drivers of the emergence and transmission of the disease: {}\"\n",
    "output_path = \"./results/\"\n",
    "checkpoint = None  # or specify a checkpoint path\n",
    "column_name = \"Text\"  # specify the column to be used for the analysis\n",
    "\n",
    "# Call the main function\n",
    "main(work, model, sub_data, column_name, prompt_text, output_path, checkpoint)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
