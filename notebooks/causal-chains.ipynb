{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causality mining using OpenAI API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "# from sklearn.metrics.pairwise import cosine_distances\n",
    "from IPython.display import display, Markdown\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Read API key from the .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "who_data = pd.read_csv(\"../data/corpus.csv\")\n",
    "who_data_epi = who_data[who_data[\"InformationType\"] == \"Epidemiology\"]\n",
    "who_data_assessment = who_data[who_data[\"InformationType\"] == \"Assessment\"]\n",
    "who_data_epi_and_assessment = who_data[who_data[\"InformationType\"].isin([\"Epidemiology\", \"Assessment\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#import 3.Clustering Drivers.xlsx, sheet \"Sheet1\"\n",
    "driver_cat = pd.read_excel(\"../data/3. Clustering Drivers.xlsx\", sheet_name=\"V2_Peter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function defnition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "### Prompt Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class PromptDesigner:\n",
    "    def __init__(self):\n",
    "        # Store different parts of the prompt as class attributes\n",
    "        self.persona_task_description = \"\"\"\n",
    "        You are an epidemiologist tasked with identifying sentences or phrases from outbreak reports that describe the drivers or contributors to the emergence or transmission of emerging pests and pathogens.\n",
    "        \"\"\"\n",
    "\n",
    "        self.domain_localization = \"\"\"\n",
    "        Here is the definition of DPSIR (Drivers, Pressure, State, Impacts, and Responses) framework, where it shows how drivers are associated with the emergence of disease.\n",
    "        Drivers: underlying socio-economic, environmental, or ecological forces that create conditions favourable for how a disease emerges, spreads or sustains transmission in human, animals or plants.\n",
    "        Pressure: human anthropogenic activities that are mainly responsible for the chances of spillover events and the transmission of pests and pathogens.\n",
    "        State: the current circulation of pests and pathogens, represented as either new case detected, an endemic, an epidemic or a pandemic.\n",
    "        Impacts: the effects caused by pests and pathogens on individuals, communities' socio-economic, and political.\n",
    "        Responses: the actions and interventions taken by governments to manage the occurrence of drivers and pressures, and to control the spread of pests and pathogens and to mitigate the impacts.\n",
    "        \"\"\"\n",
    "\n",
    "        self.causality_definition = \"\"\"\n",
    "        Causality definition: In the reports, causality can take two forms. The first form is \"Intra-sentence causality\", where the “cause” and the “effect” lie in a single sentence, while in \"Inter-sentence causality\", the “cause” and the “effect” lie in different sentences.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.extraction_guide = \"\"\"\n",
    "        Input text: The sudden appearance of unlinked cases of mpox in South Africa without a history of international travel, the high HIV prevalence among confirmed cases, and the high case fatality ratio suggest that community transmission is underway, and the cases detected to date represent a small proportion of all mpox cases that might be occurring in the community; it is unknown how long the virus may have been circulating. This may in part be due to the lack of early clinical recognition of an infection with which South Africa previously gained little experience during the ongoing global outbreak, potential pauci-symptomatic manifestation of the disease, or delays in care-seeking behaviour due to limited access to care or fear of stigma.\n",
    "        \n",
    "        Expected output\n",
    "        1. Raw text with marked causes and effects\n",
    "        The sudden appearance of unlinked cases of mpox in South Africa without a history of international travel, the high HIV prevalence among confirmed cases, and the high case fatality ratio suggest that (E1) community transmission (E1) is underway, and the cases detected to date represent a small proportion of all mpox cases that might be occurring in the community; it is unknown how long the virus may have been circulating. This may in part be due to the (C1) lack of early clinical recognition of an infection (C1) with which South Africa previously gained little experience during the ongoing global outbreak, potential (C1) pauci-symptomatic manifestation of the disease (C1), or (C1, E2) delays in care-seeking behavior (C1, E2) due to (C2) limited access to care (C2) or (C2) fear of stigma (C2).\n",
    "       \n",
    "        2. Extracted causes and effects\n",
    "        C1: lack of early clinical recognition of an infection -> E1: community transmission \n",
    "        C1: pauci-symptomatic manifestation of the disease -> E1: community transmission \n",
    "        C1: delays in care-seeking behavior -> E1: community transmission \n",
    "        C2: limited access to care -> E2: delays in care-seeking behaviour\n",
    "        C2: fear of stigma -> E2: delays in care-seeking behaviour delays in care-seeking behaviour  \n",
    "        \"\"\"\n",
    "\n",
    "        self.few_shot_examples = \"\"\"\n",
    "        Below are some examples how causality can be reported in different forms:\n",
    "        - Single cause, single effect (Type 1)\n",
    "\n",
    "        Example 1: (C1) High population density and mobility in urban areas (C1) have facilitated (E1) the rapid spread of the virus (E1)\". \n",
    "\n",
    "        Example 2: There is (C1) no vaccine for Influenza A(H1N1)v infection currently licensed for use in humans (C1). Seasonal influenza vaccines against human influenza viruses are generally not expected to protect people from (E1) infection with influenza viruses (E1) that normally circulate in pigs, but they can reduce severity.\n",
    "\n",
    "\n",
    "        - Single cause, multiple effects (Type 2)\n",
    "\n",
    "        Example 3: Several countries including Cameroon, Ethiopia, Haiti, Lebanon, Nigeria (north-east of the country), Pakistan, Somalia, Syria and the Democratic Republic of Congo (eastern part of the country) are in the midst of complex (C1) humanitarian crises (C1) with (E1) fragile health systems (E1), (E1) inadequate access to clean water and sanitation (E1) and have (E1) insufficient capacity to respond to the outbreaks (E1)\n",
    "\n",
    "        - Multiple causes, single effect (Type 3)\n",
    "        Example 4: Moreover, (C1) a low index of suspicion (C1), (C1) socio-cultural norms (C1), (C1) community resistance (C1), (C1) limited community knowledge regarding anthrax transmission (C1), (C1) high levels of poverty (C1) and (C1) food insecurity (C1), (C1) a shortage of available vaccines and laboratory reagents (C1), (C1) inadequate carcass disposal (C1) and (C1) decontamination practices (C1) significantly contribute to hampering (E1) the containment of the anthrax outbreak (E1).\n",
    "\n",
    "        Example 5:\n",
    "        The (E1) risk at the national level (E1) is assessed as 'High' due to the following:\n",
    "        + In other parts of Timor-Leste (C1) health workers have limited knowledge dog bite and scratch case management (C1) including PEP and RIG administration\n",
    "        + (C2) Insufficient stock of human rabies vaccines (C2) in the government health facilities.\n",
    "\n",
    "        - Multiple causes, multiple effects (Type 4) - Chain of causalities\n",
    "        The text may describe a chain of causality, where one effect becomes then the cause of another effect. To describe the chain, you should number the causes and effects. For example, cause 1 (C1) -> effect 1 (E1), but since effect 1 is also cause of effect 2, you should do cause 1 (C1) -> effect 1 (E1, C2) -> effect 2 (E2). \n",
    "\n",
    "        Example 6: (E2) The risk of insufficient control capacities (E2) is considered high in Zambia due to (C1) concurrent public health emergencies in the country (cholera, measles, COVID-19) (C1) that limit the country’s human and (E1, C2) financial capacities to respond to the current anthrax outbreak adequately (E1, C2).\n",
    "\n",
    "        Example 7: (C1) Surveillance systems specifically targeting endemic transmission of chikungunya or Zika are weak or non-existent (C1) -> (E1, C2) Misdiagnosis between diseases  & Skewed surveillance (E1, C2) -> (E2, C3) Misinform policy decisions (E2, C3) -> (E3)reduced accuracy on the estimation of the true burden of each diseases (E3), poor risk assessments (E3), and non optimal clinical management and resource allocation (E3). \n",
    "\n",
    "        Example 8: (C1) Changes in the predominant circulating serotype (C1) -> (E1, C2) increase the population risk of subsequent exposure to a heterologous DENV serotype (E1, C2), -> (E2) which increases the risk of higher rates of severe dengue and deaths (E2).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.negative_cases = \"\"\"\n",
    "        Irrelevant causality (negative cases): Some sentences contain causal relationships, but the effect may not be related to the disease transmission or emergence. Avoid classifying those causal relationships.\n",
    "\n",
    "        Example 1 (no causality): Because these viruses continue to be detected in swine populations worldwide, further human cases following direct or indirect contact with infected swine can be expected.\n",
    "\n",
    "        Example 2 (no relevant causality): There is some (E1) pressure on the healthcare capacity (E1) due to the (C1) very high number of admissions for dengue (C1); (C1) high vector density (C1); and an (C1) anticipated prolonged monsoon (C1). \n",
    "\n",
    "        Example 3 (no relevant causality): (C1) MVD is a highly virulent disease (C1) that can cause (E1) haemorrhagic fever (E1) and is clinically similar to Ebola virus disease.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.mechanism_of_causality = \"\"\"\n",
    "        When the text describes/list possible mechanisms behind the cause of transmission or emergence, tag them with (M). A mechanism of causality describes the specific interactions between the pathogen, host, and environment that causes the transmission / emergence. They often describe interactions at the physiological level. \n",
    "\n",
    "        Example 1: The global outbreak 2022 — 2024 has shown that (C1) sexual contact (C1) enables faster and more efficient (E1) spread of the virus (E1) from one person  to another due to (M1) direct contact of mucous membranes between people (M1), (M1) contact with multiple partners (M1), (M1) a possibly shorter incubation period on average (M1), and (M1) a longer infectious period for immunocompromised individuals (M1).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.sign_of_causality = \"\"\"\n",
    "        For each cause-effect relationship, indicate whether each cause (C) is positive (C+) or negative (C-) and each effect (E) is positive (E+) or negative (E-). \n",
    "        Use the list of positive and negative sign words provided to help determine the sign of each cause and effect. Be mindful of sentences with negations (e.g., “does not improve”), which reverses polarity. \n",
    "        Positive sign words: increase, facilitate, support, improve, expand, promote, enable, enhance, accelerate, advance, grow, boost, strengthen, benefit, contribute, progress, initiate, develop, elevate, stimulate, alleviate, optimize, revitalize. \n",
    "        Negative sign words: limit, decrease, reduce, hamper, hinder, restrict, suppress, impair, inhibit, undermine, challenge, disrupt, lack, insufficient, incomplete, challenge, deficit, obstacle, barrier, diminish, shortage, scarcity, obstruct, worsen, decline. \n",
    "\n",
    "        Example 1: “(C1-) a lack of timely access to diagnostics in many areas (C1-), (C1-) incomplete epidemiological investigations (C1-), (C1-) challenges in contact tracing and extensive but inconclusive animal investigations (C1-) continue to hamper rapid response (E1-)”\n",
    "\n",
    "        Example 2: Moreover, (C1-) a low index of suspicion (C1-), (C1) socio-cultural norms (C1), (C1) community resistance (C1), (C1-) limited community knowledge regarding anthrax transmission (C1-), (C1+) high levels of poverty (C1+) and (C1) food insecurity (C1), (C1-) a shortage of available vaccines and laboratory reagents (C1-), (C1-) inadequate carcass disposal (C1-) and (C1) decontamination practices (C1) significantly contribute to hampering (E1-) the containment of the anthrax outbreak (E1-).\n",
    "        \"\"\"\n",
    "\n",
    "    def generate_prompt(self, include_persona=False, include_domain=False, include_causality=False, include_guidance = False, include_examples=False, include_negative=False, include_mechanism=False, include_sign=False):\n",
    "        \"\"\"\n",
    "        Dynamically generate a prompt based on the specified parts.\n",
    "        \"\"\"\n",
    "        # Start with an empty prompt\n",
    "        prompt = \"\"\n",
    "\n",
    "        # Append parts based on the arguments provided\n",
    "        if include_persona:\n",
    "            prompt += self.persona_task_description + \"\\n\"\n",
    "        \n",
    "        if include_domain:\n",
    "            prompt += self.domain_localization + \"\\n\"\n",
    "        if include_causality:\n",
    "            prompt += self.causality_definition + \"\\n\"\n",
    "        if include_guidance:\n",
    "            prompt += self.extraction_guide + \"\\n\"\n",
    "        if include_examples:\n",
    "            prompt += self.few_shot_examples + \"\\n\"\n",
    "        if include_negative:\n",
    "            prompt += self.negative_cases + \"\\n\"\n",
    "        if include_mechanism:\n",
    "            prompt += self.mechanism_of_causality + \"\\n\"\n",
    "        if include_sign:\n",
    "            prompt += self.sign_of_causality + \"\\n\"\n",
    "\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causality Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Function to split text into chunks\n",
    "def batch(iterable, n=1):\n",
    "    \"\"\"Utility function to batch sentences into chunks.\"\"\"\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "class CausalChain:\n",
    "    def __init__(self, dataframe, prompt_designer=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.outlines = []  # Store a list of dictionaries to represent complex relationships\n",
    "        self.prompt_designer = prompt_designer if prompt_designer else PromptDesigner()\n",
    "        self.processed_chunks = set()  # Track processed chunks to avoid repetition\n",
    "\n",
    "    def create_effects(self, batch_size=16, prompt_parts={}):\n",
    "        print(\"Extracting causal relationships from text...\")\n",
    "\n",
    "        with open(\"api_responses.md\", \"w\", encoding=\"utf-8\") as file:\n",
    "            for index, row in tqdm(self.dataframe.iterrows(), total=self.dataframe.shape[0]):\n",
    "                text = row['Text']\n",
    "                don_id = row['DonID_standardized']\n",
    "\n",
    "                # Split text into sentences and then into chunks of 3 sentences\n",
    "                sentences = text.split(\". \")\n",
    "                chunks = [\". \".join(a) + \".\" for a in batch(sentences, 3)]\n",
    "\n",
    "                for chunk in chunks:\n",
    "                    # Skip if the chunk has already been processed\n",
    "                    if (don_id, chunk) in self.processed_chunks:\n",
    "                        continue\n",
    "\n",
    "                    cause_effect_pairs, raw_texts, causality_types, response_text = self.extract_cause_effect_openai(chunk, prompt_parts, don_id)\n",
    "\n",
    "                    # Mark the chunk as processed\n",
    "                    self.processed_chunks.add((don_id, chunk))\n",
    "\n",
    "                    # Write the response to the file immediately after receiving it\n",
    "                    file.write(f\"\\n\\n## API Response for Article ID {don_id}:\\n\\n{response_text}\\n\\n\")\n",
    "\n",
    "                    if not cause_effect_pairs and not raw_texts:\n",
    "                        self.outlines.append({\n",
    "                            \"DonId\": don_id,\n",
    "                            \"Cause\": None,\n",
    "                            \"Effect\": None,\n",
    "                            \"Causality_Type\": \"No relevant causality\",\n",
    "                            \"Raw_Text\": chunk\n",
    "                        })\n",
    "                        print(f\"No cause-effect pairs found for chunk: {chunk}\")\n",
    "\n",
    "                    for pair, raw_text, causality_type in zip(cause_effect_pairs, raw_texts, causality_types):\n",
    "                        cause, effect = pair\n",
    "                        # Remove markers like \"E1:\" from the effect\n",
    "                        effect = effect.split(\":\", 1)[-1].strip() if effect and \":\" in effect else effect\n",
    "                        self.outlines.append({\n",
    "                            \"DonId\": don_id,\n",
    "                            \"Cause\": cause,\n",
    "                            \"Effect\": effect,\n",
    "                            \"Causality_Type\": causality_type,\n",
    "                            \"Raw_Text\": raw_text\n",
    "                        })\n",
    "\n",
    "        # Print the raw texts, causes, effects, and types of causality\n",
    "        if self.outlines:\n",
    "            for outline in self.outlines:\n",
    "                print(f\"DonId: {outline['DonId']}\")\n",
    "                print(f\"Raw Text: {outline['Raw_Text']}\")\n",
    "                print(f\"Cause: {outline['Cause']}\")\n",
    "                print(f\"Effect: {outline['Effect']}\")\n",
    "                print(f\"Causality Type: {outline['Causality_Type']}\")\n",
    "                print(\"\\n\")\n",
    "        else:\n",
    "            print(\"No cause-effect pairs found in the entire dataset.\")\n",
    "\n",
    "    def extract_cause_effect_openai(self, chunk, prompt_parts={}, don_id=None):\n",
    "        # Use the PromptDesigner to generate the customized prompt\n",
    "        prompt = self.prompt_designer.generate_prompt(**prompt_parts)\n",
    "\n",
    "        # Append the text chunk to the prompt and provide a clear format for the response\n",
    "        full_prompt = f\"\"\"{prompt}\n",
    "\n",
    "        Input text: {chunk}\n",
    "\n",
    "        Expected output format:\n",
    "        1. Raw text with marked causes and effects:\n",
    "        [Provide the input text with marked causes and effects]\n",
    "\n",
    "        2. Extracted causes and effects:\n",
    "        C1: [cause] -> E1: [effect], Causality type: [T1/T2/...]\n",
    "        C2: [cause] -> E2: [effect], Causality type: [T1/T2/...]\n",
    "        ...\n",
    "        \"\"\"\n",
    "\n",
    "        # Call the OpenAI API\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": full_prompt}],\n",
    "            max_tokens=2048,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        response_text = response.choices[0].message.content\n",
    "        print(f\"API Response for Article ID {don_id}: {response_text}\")  # Print the API response for debugging\n",
    "        return self.parse_response(response_text) + (response_text,)\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_response(response_text):\n",
    "        cause_effect_pairs = []\n",
    "        raw_texts = []\n",
    "        causality_types = []  # Store the causality types\n",
    "\n",
    "        if not response_text.strip():\n",
    "            print(\"Empty response received from API.\")\n",
    "            return cause_effect_pairs, raw_texts, causality_types\n",
    "\n",
    "        # Parse the response based on the expected output format\n",
    "        lines = response_text.split(\"\\n\")\n",
    "        raw_text_section = False\n",
    "        extracted_pairs_section = False\n",
    "        raw_text = \"\"\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "\n",
    "            if line.startswith(\"1. Raw text with marked causes and effects\"):\n",
    "                raw_text_section = True\n",
    "                extracted_pairs_section = False\n",
    "                raw_text = \"\"  # Reset raw text for each new section\n",
    "                continue\n",
    "\n",
    "            if line.startswith(\"2. Extracted causes and effects\"):\n",
    "                raw_text_section = False\n",
    "                extracted_pairs_section = True\n",
    "                continue\n",
    "\n",
    "            if raw_text_section and line:\n",
    "                raw_text += line + \" \"\n",
    "\n",
    "            if extracted_pairs_section:\n",
    "                if line.startswith(\"C\") and \"->\" in line:\n",
    "                    try:\n",
    "                        cause = line.split(\":\")[1].split(\"->\")[0].strip()\n",
    "                        effect = line.split(\"->\")[1].split(\", Causality type:\")[0].strip()\n",
    "                        causality_type = line.split(\"Causality type:\")[1].strip()\n",
    "                        #! Remove markers like \"E1:\" from the effect\n",
    "                        effect = effect.split(\":\", 1)[-1].strip() if effect and \":\" in effect else effect\n",
    "                        cause_effect_pairs.append((cause, effect))\n",
    "                        raw_texts.append(raw_text.strip())\n",
    "                        causality_types.append(causality_type)\n",
    "                    except IndexError:\n",
    "                        print(f\"Malformed line: {line}\")\n",
    "                #! Process No causality line\n",
    "                # elif line.lower().startswith(\"no relevant causality\") or line.lower().startswith(\"there are no relevant causes\"):\n",
    "                elif \"->\" not in line:\n",
    "                    cause_effect_pairs.append((None, None))\n",
    "                    raw_texts.append(raw_text.strip())\n",
    "                    causality_types.append(\"No causality\")\n",
    "\n",
    "        return cause_effect_pairs, raw_texts, causality_types\n",
    "\n",
    "def create_causes_effects_dataframe(outlines):\n",
    "    # Create a DataFrame from the outlines list\n",
    "    dataframe = pd.DataFrame(outlines)\n",
    "\n",
    "    # Ensure all expected columns are present, fill with 'Unknown' if missing\n",
    "    for column in [\"DonId\", \"Cause\", \"Effect\", \"Causality_Type\", \"Raw_Text\"]:\n",
    "        if column not in dataframe:\n",
    "            dataframe[column] = \"Unknown\"\n",
    "\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "prompt_designer = PromptDesigner()\n",
    "\n",
    "prompt_parts = {\n",
    "    \"include_persona\": True,\n",
    "    \"include_domain\": True,\n",
    "    \"include_causality\": True,\n",
    "    \"include_guidance\": True,\n",
    "    \"include_examples\": True,\n",
    "    \"include_negative\": True,\n",
    "    \"include_mechanism\": False,\n",
    "    \"include_sign\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "example_data = who_data_assessment.iloc[0:30]\n",
    "\n",
    "\n",
    "# Create a CausalChain instance with the dataset\n",
    "causal_chain = CausalChain(dataframe=example_data, prompt_designer=prompt_designer)\n",
    "\n",
    "# Generate effects based on the chunks of text\n",
    "causal_chain.create_effects(prompt_parts=prompt_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with the causes, effects, and other related information\n",
    "result_df = create_causes_effects_dataframe(causal_chain.outlines)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Export data to csv\n",
    "result_df.to_csv('result_df_31 Oct.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drivers Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Import result_df_31 Oct.csv\n",
    "result_df = pd.read_csv('../data/result_df_31 Oct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get a summary for each cause-effect pair\n",
    "def get_summary(text):\n",
    "    prompt = (\n",
    "        f\"Analyze the following text to identify common categories related to drivers of infectious diseases. \"\n",
    "        f\"Avoid mentioning specific diseases or too specific terms. \"\n",
    "        f\"Summarize the text into two words only. For example:\\n\"\n",
    "        f\"- Text: 'transmission of ebola' -> Summary: 'disease transmission'\\n\"\n",
    "        f\"- Text: 'COVID-19 infection' -> Summary: 'disease transmission'\\n\"\n",
    "        f\"Please summarize the following: '{text}'\"\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=100,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Apply function to each row in cause and effect columns\n",
    "result_df['Cause_category'] = result_df['Cause'].apply(get_summary)\n",
    "result_df['Effect_category'] = result_df['Effect'].apply(get_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using predefined list to categorize drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Sort column \"Consolidated Name\" and remove duplicates in that column, write in method chaining and save to new object\n",
    "driver_cat_rm_dups = (\n",
    "    driver_cat\n",
    "    .rename(columns={\"Peter's name\": \"Category\"})\n",
    "    .assign(Category=lambda df: df['Category'].ffill()) # fill the data of column \"Category\" by the value above it for missing values\n",
    "    .drop_duplicates(subset=[\"Category\", \"Consolidated Name\"])\n",
    ") \n",
    "\n",
    "predefined_driver_category = (\n",
    "    driver_cat_rm_dups\n",
    "    .groupby(\"Category\")[\"Consolidated Name\"]\n",
    "    .apply(lambda x: x.dropna().unique().tolist())\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "print(predefined_driver_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def format_prompt(text, category_dict):\n",
    "    # Format the dictionary into a string for the prompt\n",
    "    category_examples = \"\\n\".join(\n",
    "        f\"- {category}: {', '.join(consolidated_names[:50])}...\"  \n",
    "        for category, consolidated_names in category_dict.items()\n",
    "    )\n",
    "    \n",
    "    # Construct the prompt\n",
    "    prompt = (\n",
    "        f\"Analyze the following text and map it to a predefined category from the list below. \"\n",
    "        f\"Return the output in this exact format:\\n\"\n",
    "        f\"consolidate_name: [name], category: [category]\\n\\n\"\n",
    "        f\"Categories and examples:\\n{category_examples}\\n\\n\"\n",
    "        f\"Example mappings:\\n\"\n",
    "        f\"- Text: 'Socio-economic factors, high levels of poverty' -> consolidate_name: socioeconomic, category: Economy\\n\"\n",
    "        f\"- Text: 'favorable conditions for vector populations during the monsoon season in affected areas' -> consolidate_name: climate, category: Climate/Weather\\n\"\n",
    "        f\"- Text: 'Lack of laboratory capacity' -> consolidate_name: infrastructure, category: Build infrastructure\\n\\n\"\n",
    "        f\"In case you cannot match the orginal text with any of the consolidated names, but the original text is about diseases transmission process\\n\\n\"\n",
    "        f\"Summarize the text into two words only for the consolidate_name. Avoid mentioning specific diseases or too specific terms. For example:\\n\"\n",
    "        f\"- Text: 'contact with infected poultry or environments that have been contaminated' -> consolidate_name: 'poultry exposure', category: Disease transmission\\n\"\n",
    "        f\"- Text: 'close contact with A(H5N1)-infected live or dead birds or mammals' -> consolidate_name: 'animal exposure', category: Disease transmission\\n\"\n",
    "        f\"If none of the above applies, please return consolidate_name: 'Undefined', category: Undefined\\n\\n\"\n",
    "        f\"Now, analyze the following text:\\n\"\n",
    "        f\"'{text}'\\n\"\n",
    "        f\"Provide your answer in this format: consolidate_name: [name], category: [category]\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def get_summary_with_prelist(text, category_dict):\n",
    "    # Format the prompt with the dictionary\n",
    "    prompt = format_prompt(text, category_dict)\n",
    "    \n",
    "    # Send the prompt to OpenAI\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=100,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_text = response.choices[0].message.content\n",
    "    print(f\"API Response: {response_text}\")  # Debugging line\n",
    "    \n",
    "    # Extract consolidate_name and category\n",
    "    try:\n",
    "        if response_text.startswith(\"consolidate_name:\") and \", category:\" in response_text:\n",
    "            consolidate_name, category = map(str.strip, response_text.split(\", category:\"))\n",
    "            consolidate_name = consolidate_name.replace(\"consolidate_name:\", \"\").strip()\n",
    "            category = category.replace(\"'\", \"\").strip()\n",
    "            return consolidate_name, category\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing response: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def categorize_text(row, column_name, category_dict):\n",
    "    \"\"\"\n",
    "    Categorize the text from the specified column using OpenAI and the category dictionary.\n",
    "    \"\"\"\n",
    "    consolidate_name, category = get_summary_with_prelist(row[column_name], category_dict)\n",
    "    return pd.Series({f'{column_name}_consolidate_name': consolidate_name, f'{column_name}_category_new': category})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "result_df = result_df.apply(\n",
    "    lambda row: pd.concat([\n",
    "        pd.Series(row),  # Keep the original row data\n",
    "        categorize_text(row, 'Cause', predefined_driver_category),  # Add Cause-related columns\n",
    "        categorize_text(row, 'Effect', predefined_driver_category)  # Add Effect-related columns\n",
    "    ]),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "(result_df\n",
    " .filter(['DonId', 'Cause', 'Cause_consolidate_name', 'Cause_category_new', 'Effect', 'Effect_consolidate_name', 'Effect_category_new']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "result_df.to_csv('../data/result_df_19 Nov.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('../data/result_df_19 Nov.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "new_df = result_df[['Cause', 'Cause_category', 'Cause_consolidate_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP algorithms\n",
    "\n",
    "- Sentence Embeddings with Clustering: Create a vector capturing semantic meaning, then using clustering algorithms like K-Mean, Hierarchical Clustering, DBSCAN\n",
    "- Topic Modeling: Latent Dirichlet Allocation (LDA) or Non-Negative Matrix Factorization (NMF) -> typically used for longer texts\n",
    "- Text Similarity using Cosine Similarity and Clustering\n",
    "- Self-Supervised Clustering with Transformers: BERTopic uses transformer embeddings with dimensionality reduction and topic representation, enabling a more dynamic clustering approach suitable for nuanced or dense datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cosine_test = pd.read_csv('result_df_31 Oct.csv')\n",
    "\n",
    "# Create a list of unique categories\n",
    "unique_drivers_categories = list(set(cosine_test['Cause_category'].tolist() + cosine_test['Effect_category'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Load the transformer model\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Encode the unique categories\n",
    "category_embeddings = model.encode(unique_drivers_categories, convert_to_tensor=True)\n",
    "\n",
    "# Generate embeddings for each unique category\n",
    "category_embeddings = model.encode(unique_drivers_categories, convert_to_tensor=True)\n",
    "\n",
    "# Calculate the cosine similarity matrix\n",
    "cosine_similarity_matrix = util.pytorch_cos_sim(category_embeddings, category_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Convert cosine similarities to distances for clustering\n",
    "cosine_distance_matrix = 1 - cosine_similarity_matrix.cpu().numpy()\n",
    "\n",
    "# Apply Agglomerative Clustering\n",
    "clustering_model = AgglomerativeClustering(\n",
    "    metric='precomputed',\n",
    "    linkage='average',\n",
    "    n_clusters=5  # Choose the number of clusters or use distance_threshold\n",
    ")\n",
    "cluster_labels = clustering_model.fit_predict(cosine_distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame for unique categories and their cluster labels\n",
    "clustered_categories = pd.DataFrame({\n",
    "    'category': unique_drivers_categories,\n",
    "    'cluster': cluster_labels\n",
    "})\n",
    "\n",
    "# Display grouped categories\n",
    "display(clustered_categories.sort_values(by='cluster'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Merge cluster labels for Cause and Effect categories back\n",
    "cosine_test = cosine_test.merge(clustered_categories, left_on='Cause_category', right_on='category', how='left').rename(columns={'cluster': 'Cause_cluster'}).drop(columns=['category'])\n",
    "cosine_test = cosine_test.merge(clustered_categories, left_on='Effect_category', right_on='category', how='left').rename(columns={'cluster': 'Effect_cluster'}).drop(columns=['category'])\n",
    "\n",
    "# Display result with cluster labels\n",
    "display(cosine_test[['Cause_category', 'Cause_cluster', 'Effect_category', 'Effect_cluster']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cosine_test.to_csv('cosine_test_31 Oct.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Map embeddings for Cause and Effect categories\n",
    "cosine_test['Cause_embedding'] = cosine_test['Cause_category'].apply(lambda x: category_embedding_dict[x])\n",
    "cosine_test['Effect_embedding'] = cosine_test['Effect_category'].apply(lambda x: category_embedding_dict[x])\n",
    "\n",
    "# Calculate cosine similarity between each Cause and Effect embedding\n",
    "cosine_test['cosine_similarity'] = cosine_test.apply(\n",
    "    lambda row: util.pytorch_cos_sim(row['Cause_embedding'], row['Effect_embedding']).item(),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(cosine_test[['Cause_category', 'Effect_category', 'cosine_similarity']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Grouping by DonId and calculating the percentage of \"No causality\"\n",
    "def calculate_no_relevant_causality_percentage(df):\n",
    "    grouped = df.groupby('DonId')['Causality_Type'].apply(lambda x: (x == 'No causality').mean() * 100)\n",
    "    return grouped\n",
    "\n",
    "# Example usage\n",
    "# Assuming `df` is your dataframe created from the outlines\n",
    "grouped_percentage = calculate_no_relevant_causality_percentage(result_df)\n",
    "print(grouped_percentage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
